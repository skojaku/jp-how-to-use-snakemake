from os.path import join

#
# Raw data
#
WIKI_PAGE_TITLE = ["Sapporo", "Otaru"]

#
# Preprocessed data
#
TEXT_DATA = join("data", "wiki_text_wikititle={wikititle}.txt")
SUMMARIZED_TEXT = join(
    "data", "summary_wikititle={wikititle}_model={model}_len={max_length}.csv"
)


#
# Model & Parameters
#
# see https://huggingface.co/models?pipeline_tag=summarization&sort=downloads
MODEL_LIST = ["t5-base", "t5-small"]
MAX_LENGTH_LIST = [32, 128]  # Length of the summarized text


rule all:
    input:
        expand(
            SUMMARIZED_TEXT,
            wikititle=WIKI_PAGE_TITLE,
            model=MODEL_LIST,
            max_length=MAX_LENGTH_LIST,
        ),


rule retrieve_wiki_text:
    output:
        TEXT_DATA,
    params:
        wikititle=lambda wildcards: wildcards.wikititle,
    shell:
        "python workflow/get-wikipages.py {params.wikititle} {output}"


rule summary:
    input:
        TEXT_DATA,
    output:
        SUMMARIZED_TEXT,
    params:
        max_length=lambda wildcards: wildcards.max_length,
        model=lambda wildcards: wildcards.model,
    shell:
        "python workflow/summarize.py {input} {params.model} {params.max_length} {output}"
