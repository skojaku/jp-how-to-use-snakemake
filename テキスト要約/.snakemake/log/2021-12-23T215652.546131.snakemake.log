Building DAG of jobs...
Using shell: /usr/local/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                   count    min threads    max threads
------------------  -------  -------------  -------------
all                       1              1              1
retrieve_wiki_text        3              1              1
summary                  54              1              1
total                    58              1              1

Select jobs to execute...

[Thu Dec 23 21:56:53 2021]
rule summary:
    input: data/wiki_text_wikititle=Kushiro.txt
    output: data/summary_wikititle=Kushiro_model=t5-base_len=512.csv
    jobid: 44
    wildcards: wikititle=Kushiro, model=t5-base, max_length=512
    resources: tmpdir=/var/folders/57/9xrg5s891dzfv2s_nfnbj2y40000gq/T

[Thu Dec 23 21:57:10 2021]
Error in rule summary:
    jobid: 44
    output: data/summary_wikititle=Kushiro_model=t5-base_len=512.csv
    shell:
        python workflow/summarize.py data/wiki_text_wikititle=Kushiro.txt t5-base 512 data/summary_wikititle=Kushiro_model=t5-base_len=512.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/skojaku-admin/program/code/jp-how-to-use-snakemake/Snakemake応用編2/.snakemake/log/2021-12-23T215652.546131.snakemake.log
